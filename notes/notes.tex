% Created 2015-06-13 Sat 17:49
\documentclass[integrals, nointegrals, article, 12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{clrscode3e}
\usepackage{palatino}
\usepackage{euler}
\setcounter{secnumdepth}{2}
\geometry{a4paper, textwidth=6.5in, textheight=10in, marginparsep=7pt, marginparwidth=.6in}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\date{}
\title{Cache Optimized error correction.}
\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 24.5.1 (Org mode 8.2.8)}}
\begin{document}

\maketitle

\section{Algorithm}
\label{sec-1}
We assume that the index of array and the level number starts with
$0$.  We say a search tree \emph{complete}, if at every level $i$ of the
tree has exactly $m(m+1)^{i}$ elements. We also assume $n$ is a
multiple of $m$ and $m \geq 3$.

\begin{codebox}
\Procname{$\proc{Cache-Aware-Search-Tree}(X, m)$}
\zi \kw{Input : } List of Elements, $X$ ; No. of Elements in a cache line, $m$
\zi \kw{Output : } Cache-Aware Search Tree of the list $X$ of size $n$, $CT$
\li $l \gets \lceil \log_{m+1} (n+1) \rceil$
\li $\proc{Init-Global}(m, l)$
\li Initialize $CT$ as a vector of size $n$.
\li $i \gets 0$; $CT[0] \gets 0$; $CT[1] \gets l$; $CT[m - 1] \gets n - 1$
\li $l_{ptr} \gets 0$ \Comment Pointer to the last inserted node
\li $c_{ptr} \gets 0$ \Comment Pointer to the current node
\li \While $i < n$
    \Do
\zi      \Comment $[x,y]$ range of indices covered by this subtree.
\li      $x \gets CT[c_{ptr}]$
\li      $y \gets CT[c_{ptr} + m - 1]$
\zi      \Comment $k$ is no. levels of current subtree including root.
\li      $k \gets CT[c_{ptr} + 1]$
\li      $d \gets y - x + 1$
\li      \If $d == m$
         \Then
\li
\li      $ST \gets \proc{Subtree-Size}(y - x + 1, k)$
\li      $y \gets x$
\li      \For $j \gets 0 \To m - 1$ \Comment Update entries for current node.
         \Do
\li           $y \gets y + ST[j]$
\li           $CT[c_{ptr} + j] \gets y$
         \End
\li      \For $j \gets 0 \To m$ \Comment Insert indices for sub-trees.
         \Do
\li           \If $ST[j] > 0$
              \Do
\li               $y \gets x + ST[j]$
\li               $l_{ptr} \gets l_{ptr} + m$
\li               $CT[l_{ptr}] \gets x$
\li               $CT[l_{ptr} + 1] \gets k - 1$
\li               $CT[l_{ptr} + m - 1] \gets y - 1$
\li               $x \gets y + 1$
              \End
        \End
\li     $i = i + m$; $c_{ptr} = c_{ptr} + m$
    \End
\li \Return $CT$
\end{codebox}

\begin{codebox}
\Procname{$\proc{Init-Global}(m, l)$}
\zi $A_1, A_2$ are global arrays of size $l$ each.
\li Initialize $A_1$ with $A_1[i] = m(m+1)^{i}$.
\zi \quad $A_1[i]$ is the number of elements at level $i$ of a
    complete $m$-ary search tree.
\li Initialize $A_2$ with $A_2[i] = \sum_{j = 0}^i A_1[j]$.
\zi \quad $A_2[i]$ is the total number of elements at upto
    level $i$ of a complete $m$-ary search tree.
\end{codebox}

\begin{codebox}
\Procname{$\proc{Subtree-Size}(d,k)$}
\zi \kw{Input : } No. of elements with in this subtree, $d$
\zi \kw{Input : } No. of Levels in the current subtree incl. root, $k$
\zi \kw{Output : } Size of each of the $m+1$ subtree sizes, $ST$
\li \If $d == m$ \Comment Last row : All zeroes
\li \Do Initialize $ST$ to $m+1$ zeros.
\li     \Return $ST$ \End
\li $d_k \gets d - A_2[k - 2]$ \Comment No. of elements in the last level
\li $q = d_k / A_1[k - 2]$
\li $r = d_k \% A_1[k - 2]$
\zi \Comment $LS$, No. elements in last row of $m+1$ sub-trees.
\li \For $j \gets 0 \To m$
\li \Do \If $j < q$
\li        \Then $LS[j] \gets A_1[k - 2]$
\li      \ElseIf $j > q$
\li        \Then $LS[j] \gets 0$
\li      \Else
\li         $LS[j] \gets r$ \End
    \End
\zi \Comment $ST$, Size of $m+1$ sub-trees
\li \For $j \gets 0 \To m$
\li \Do $ST[j] = LS[j] + A_2[k-2]$ \End
\li \Return $ST$
\end{codebox}


\section{Experimental Results}
\label{sec-2}

In order to demonstate how the layout datastructures behave with real
datasets, we used the datasets listed in table
\ref{tab:datasets}. Datasets are the same as that one used in (TODO: Refer
parallel error correction paper) and are available from the NCBI Short
Read Archive.

\begin{table}[htb]
\caption{\label{tab:datasets}Datasets for experimental validation}
\centering
\begin{tabular}{llrrr}
\hline
Dataset & Genome & No. of Reads & Read Length & Coverage\\
 &  & (millions) & (base pairs) & \\
\hline
D2 & \emph{E.Coli} & 8.9 & 101 & 193x\\
D3A & \emph{Droso. M} & 37.9 & 95 & 30x\\
D3B & \emph{Droso. M} & 41.5 & 35 & 12x\\
D3C & \emph{Droso. M} & 18.8 & 75 & 12x\\
\hline
\end{tabular}
\end{table}


Datasets D3A (SRX023452), D3B (SRX001651) and D3C(SRX001652) are
combined into a single dataset D3, having 98.2 million
reads. D2(SRR034501$\backslash$$_{\text{1}}$) and D3 are used in all our experiments. Since we
use the same parameters as used in (TODO: refer to the error correction
paper), we don't evaluate the quality of error correction. We only
evaluate the runtime performace for error correction runs of the
datasets D2 and D3 with the three different -- sorted order layout,
cache aware layout and cache oblivious layout.



\section{Results}
\label{sec-3}
\subsection{Kmer Table Sizes}
\label{sec-3-1}

\begin{table}[htb]
\caption{\label{tab:spectrum}$k$-mer spectrum and tile spectrum size}
\centering
\begin{tabular}{lrr}
\hline
Dataset & Kmer Table Size & Tile Table Size\\
\hline
D2 & 1699218 & 8830856\\
D3 & 6092949 & 240045877\\
\hline
\end{tabular}
\end{table}


\subsection{Dataset D2 (Hamming Distance 1)}
\label{sec-3-2}
\subsubsection{Summary}
\label{sec-3-2-1}

\begin{table}[htb]
\caption{\label{tab:d2h1run}Results for dataset $D2$ with $h = 1$}
\centering
\begin{tabular}{rrrrrrr}
\hline
 & k-Spectrum & Error & Cache Aware &  & Cache Oblivious & \\
Procs & Construction & Correction & Error Correction & Speedup & Error Correction & Speedup\\
 & Time (seconds) & Time (seconds) & Time (seconds) &  & Time (seconds) & \\
\hline
2 & 74.94 & 1326.61 & 739.76 & 1.79x & 858.30 & 1.54x\\
4 & 42.61 & 761.65 & 451.68 & 1.68x & 475.62 & 1.60x\\
8 & 22.66 & 335.53 & 244.57 & 1.37x & 249.76 & 1.34x\\
16 & 13.12 & 189.28 & 133.60 & 1.41x & 130.01 & 1.44x\\
32 & 7.71 & 98.92 & 71.72 & 1.38x & 69.10 & 1.43x\\
64 & 4.90 & 52.46 & 36.42 & 1.46x & 35.79 & 1.46x\\
128 & 4.24 & 28.02 & 19.71 & 1.42x & 19.23 & 1.45x\\
256 & 5.90 & 14.25 & 10.40 & 1.37x & 10.06 & 1.42x\\
512 & 13.72 & 7.65 & 5.60 & 1.37x & 5.54 & 1.38x\\
\hline
\end{tabular}
\end{table}



\subsubsection{Default run results}
\label{sec-3-2-2}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
2 & 74.94 & 1326.61 & 1406.62\\
4 & 42.61 & 761.65 & 808.91\\
8 & 22.66 & 335.53 & 359.56\\
16 & 13.12 & 189.28 & 203.14\\
32 & 7.71 & 98.92 & 107.12\\
64 & 4.90 & 52.46 & 57.59\\
128 & 4.24 & 28.02 & 32.40\\
256 & 5.90 & 14.25 & 20.37\\
512 & 13.72 & 7.65 & 22.10\\
\hline
\end{tabular}
\end{center}


\subsubsection{Cache Aware results}
\label{sec-3-2-3}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
2 & 68.32 & 739.76 & 813.68\\
4 & 37.69 & 451.68 & 491.88\\
8 & 22.65 & 244.57 & 268.59\\
16 & 12.12 & 133.60 & 147.47\\
32 & 7.60 & 71.72 & 80.82\\
64 & 4.90 & 36.42 & 41.51\\
128 & 4.10 & 19.71 & 24.77\\
256 & 5.80 & 10.40 & 16.80\\
512 & 13.10 & 5.60 & 19.52\\
\hline
\end{tabular}
\end{center}

\subsubsection{Cache Oblivious results}
\label{sec-3-2-4}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
2 & 75.24 & 858.30 & 948.21\\
4 & 42.07 & 475.62 & 520.45\\
8 & 23.65 & 249.76 & 274.82\\
16 & 13.14 & 130.01 & 147.21\\
32 & 7.65 & 69.10 & 77.21\\
64 & 4.72 & 35.79 & 40.83\\
128 & 4.38 & 19.23 & 23.14\\
256 & 6.36 & 10.06 & 16.49\\
512 & 13.34 & 5.54 & 19.61\\
\hline
\end{tabular}
\end{center}

\subsection{Dataset D2 (Hamming Distance = 2)}
\label{sec-3-3}

\subsubsection{Summary}
\label{sec-3-3-1}

\begin{table}[htb]
\caption{\label{tab:d2h1run}Results for dataset $D2$ with $h = 1$}
\centering
\begin{tabular}{rrrrrrr}
\hline
 & k-Spectrum & Error & Cache Aware &  & Cache Oblivious & \\
Procs & Construction & Correction & Error Correction & Speedup & Error Correction & Speedup\\
 & Time (seconds) & Time (seconds) & Time (seconds) &  & Time (seconds) & \\
\hline
64 & 4.79 & 5820.63 & 2430.41 & 2.39 & 3430.27 & 1.69\\
128 & 4.06 & 2868.85 & 1315.91 & 2.18 & 1819.92 & 1.57\\
256 & 6.19 & 1627.04 & 740.60 & 2.19 & 1042.59 & 1.56\\
512 & 13.06 & 835.94 & 380.16 & 2.19 & 537.66 & 1.55\\
\hline
\end{tabular}
\end{table}

\subsubsection{Default run results}
\label{sec-3-3-2}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
64 & 4.79 & 5820.63 & 5287.87\\
128 & 4.06 & 2868.85 & 2874.39\\
256 & 6.19 & 1627.04 & 1693.27\\
512 & 13.06 & 835.94 & 908.36\\
\hline
\end{tabular}
\end{center}

\subsubsection{Cache Aware results}
\label{sec-3-3-3}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
64 & 4.83 & 2430.41 & 2495.45\\
128 & 4.10 & 1315.91 & 1321.59\\
256 & 5.86 & 740.60 & 747.63\\
512 & 14.1 & 380.16 & 394.61\\
\hline
\end{tabular}
\end{center}

\subsubsection{Cache Oblivious results}
\label{sec-3-3-4}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
64 & 4.80 & 3430.27 & 3435.68\\
128 & 4.07 & 1819.92 & 1825.67\\
256 & 6.83 & 1042.59 & 1050.28\\
512 & 13.01 & 537.66 & 551.67\\
\hline
\end{tabular}
\end{center}

\subsection{Dataset D3 (Hamming Distance 1)}
\label{sec-3-4}
\subsubsection{Default run results}
\label{sec-3-4-1}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
8 & 742.81 & 1393.49 & 2161.24\\
16 & 301.14 & 909.75 & 1242.94\\
32 & 95.42 & 521.19 & 622.65\\
64 & 56.96 & 268.58 & 328.34\\
128 & 36.03 & 139.88 & 177.49\\
256 & 27.98 & 89.03 & 117.85\\
512 & 32.55 & 53.81 & 87.44\\
\hline
\end{tabular}
\end{center}

\subsubsection{Cache Aware results}
\label{sec-3-4-2}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
8 &  &  & \\
16 & 325.56 & 597.92 & 959.25\\
32 & 95.07 & 339.56 & 440.89\\
64 & 56.71 & 177.45 & 237.06\\
128 & 36.47 & 95.91 & 133.95\\
256 & 27.65 & 57.54 & 85.99\\
512 & 31.31 & 36.12 & 68.50\\
\hline
\end{tabular}
\end{center}

\subsubsection{Cache Oblivious results}
\label{sec-3-4-3}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
8 &  &  & \\
16 & 277.21 & 591.01 & 895.64\\
32 & 95.85 & 343.65 & 442.24\\
64 & 56.62 & 175.89 & 241.81\\
128 & 36.34 & 93.65 & 135.92\\
256 & 28.24 & 60.75 & 89.78\\
512 & 31.28 & 47.29 & 81.26\\
\hline
\end{tabular}
\end{center}

\subsection{Dataset D3 (Hamming Distance = 2)}
\label{sec-3-5}
\subsubsection{Summary}
\label{sec-3-5-1}
\begin{table}[htb]
\caption{\label{tab:d3h2run}Results for dataset $D3$ with $h = 2$}
\centering
\begin{tabular}{rrrrrrr}
\hline
 & k-Spectrum & Error & Cache Aware &  & Cache Oblivious & \\
Procs & Construction & Correction & Error Correction & Speedup & Error Correction & Speedup\\
 & Time (seconds) & Time (seconds) & Time (seconds) &  & Time (seconds) & \\
\hline
256 & 27.49 & 5816.80 & 2633.96 & 2.21 & 3600.86 & 1.61\\
512 & 33.04 & 3503.59 & 1611.09 & 2.17 & 2184.29 & 1.60\\
1024 & 53.40 & 2156.35 & 1071.46 & 2.01 & 1313.32 & 1.64\\
\hline
\end{tabular}
\end{table}

\subsubsection{Default run results}
\label{sec-3-5-2}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
256 & 27.49 & 5816.80 & 5865.32\\
512 & 33.04 & 3503.59 & 3544.15\\
1024 & 53.40 & 2156.35 & 2215.19\\
\hline
\end{tabular}
\end{center}

\subsubsection{Cache Aware run results}
\label{sec-3-5-3}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
256 & 27.64 & 2633.96 & 2682.89\\
512 & 31.87 & 1611.09 & 1644.02\\
1024 & 53.62 & 1071.46 & 1130.10\\
\hline
\end{tabular}
\end{center}

\subsubsection{Cache Oblivious run results}
\label{sec-3-5-4}

\begin{center}
\begin{tabular}{rrrr}
\hline
Procs & Construction & Error Correction & Total\\
 & Time (seconds) & Time (seconds) & Time (seconds)\\
\hline
256 & 28.27 & 3600.86 & 3649.69\\
512 & 32.67 & 2184.29 & 2224.49\\
1024 & 56.61 & 1313.32 & 1373.40\\
\hline
\end{tabular}
\end{center}

\section{Work Distribution Notes}
\label{sec-4}

We will use a master-slave pattern to dynamically distribute
work. Suppose, we use p processes for the error correction, and each
process uses k + 1 shared memory threads.  In each process, we allocate
one thread completely dedicated to handle all the inter-process
communincations and work assignment. I call this thread 'the
co-ordination thread'. This thread doesn't do any error correction (EC)
work. The rest of the k worker threads will only do the EC work. In our
implementation, we will use the the root process for the master process.

In the mater process, the following are the reponsibilities of a
co-ordination thread:
\begin{enumerate}
\item Assign work to k local worker threads.
\item Poll for any work request from slave process. If any slave process
asks for work, assign work for them.
\item When there is no more work to assign, notify every one.
\end{enumerate}

In the slave process, a co-ordination thread's responsibilities are as
follows:
\begin{enumerate}
\item If we are running low on work assignment, ask work from master
process.
\item Recieve work from master process and distribute it to the local
worker threads.
\end{enumerate}

An EC work-item is represented by an offset in the input file. This is
position starting from which a worker thread starts reading and
continues to do error correction for a predifined chunk. Communication
between the co-ordination thread and the worker threads with in a
process is accomplished via a shared queue. The co-ordination thread
loads the work-item to queue, from which the worker threads pops the
item and proceeds to do the error correction. When the queue size is
below a given threshold, the co-ordination threads pre-emptively
requests work from the master process. The master process always sends k
work-items. Right now the threshold is kept as 2k, and hence the work
queue size is always bounded by 3k work items.

Worker thread is dumb in the sense that it goes on an infinite loop : it
does error correction, looks at the work queue for the next chunk and so
on. Worker processes break out of the loop, when a shared boolean
variable is set to true.

The state transitions of the co-ordination thread is as follows:
Initially, the co-ordination thread is at "ASSIGN$_{\text{WORK}}$" state. In this
state this thread in a slave process monitors the work queue, and if its
size falls below 2k, it requests work-items from the master
process. After receiving the work items, it pushes them into the work
queue. In the master process, this thread fulfills the slaves' requests,
and performs work-item assignment for local worker threads. When there
is no more work available for assignment, we move to the next state :
"PENDING$_{\text{WORK}}$". This state represents the situation that there is no
more work to assign, but the work-queue is not empty i.e., there are
still work-items left to be claimed by the dumb workers. In this state,
the co-ord thread in a slave process will just monitor the work queue
and wait for it to become empty. In the master process, the co-ord
thread at this state will poll for any slave requests, while monitoring
the work queue. This thread also sends the "No more work is available to
assign" signal by sending assigning 'zero work'. This thread can move to
next state only if it has sent 'zero work' signal to all the slave
processes. The next state is 'FINISHED$_{\text{WORK'}}$. At this state, there is
nothing more to do for the co-ord threads. It sets the shared boolean
variable to true and waits for the worker threads to finish the last
error correction work items.




Page 3:
Add SRX027713 and SRX027583 as the references for the human dataset.

Page 4: (right column: 2nd paragraph)
\begin{itemize}
\item The work-queue can hold up to 3 × M chunks at any given time.
\end{itemize}
Page 4: (right column: 4th paragraph)
\begin{itemize}
\item Each local-master is responsible for maintaining a work-queue of size
3 x M chunks.
\end{itemize}

Comment: We maintain only 2 x M work-chunks in the queue at a
time. However, the initial queue size is 3 x M work-chunks because we
want to avoid work requests from local masters as soon as the error
correction is started. Suppose if the initial queue size is less than 3
x M, which implies that after M work-chunks are taken up by the worker
threads, we will have less than 2 x M left in the queue. This
immediately causes the local master to request the global master for
work. By keeping the initial queue size 3 x M, we avoid the initial
flood of requests.

Page 4: (right column: 3rd paragraph)
\begin{itemize}
\item After communicating the no−more−work message to all the local-masters,
\end{itemize}
the global master waits for all the local-masters to complete the work
previously requested by them.

Comment : No, global-master doesn't wait for the local-master. It waits
to make sure only two things:
\begin{enumerate}
\item All local-masters have recieved the "no-more-work" message. This is
done by counting how many times "no-more-work" message has been sent.
\item global-masters' own local workers have completed their work.
\end{enumerate}
If the above two are done, global-master just go ahead and does
MPI$_{\text{finalize}}$. Here, also it doesn't wait for local-masters -- only that
it announces that there is nothing more to do.


Page 5:(left column: 1st paragraph)
\begin{itemize}
\item The local-master then sends a pending − work − done message to the
global-master and exits.
\end{itemize}

Comment : No, the local-master doesn't send any message to global
master. The "pending-work" is just a state maintained by local masters
to no longer request work from the master and just wait until every
local worker is done error correction.

Page 5:(right column: 1st paragraph)
\begin{itemize}
\item By taking the network-latency of our cluster into account, a choice of
500 reads for the chunk size achieves a good trade-off between the two
conflicting requirements.
\end{itemize}

Comment: Also, note that it also depends on the dataset on how much work
500 reads consume.

Page 7:(results)

Comment: Do we have to mention that we don't use the parallel
cache-aware construction algorithm in our experiments ?
% Emacs 24.5.1 (Org mode 8.2.8)
\end{document}